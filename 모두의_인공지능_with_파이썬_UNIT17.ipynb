{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqzkcXQTVo9GkECM4LFf1E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eunsol123/BoardMVC_JSP/blob/main/%EB%AA%A8%EB%91%90%EC%9D%98_%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5_with_%ED%8C%8C%EC%9D%B4%EC%8D%AC_UNIT17.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "corona_rnn.ipynb (전염병 예측 인공지능 만들기)"
      ],
      "metadata": {
        "id": "Mk7vnpr05Kit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential # 케라스의 모델 도구(models) 중 시퀀셜 모델을 불러오는 명령어\n",
        "\n",
        "from keras.layers import SimpleRNN, Dense # 레이어 도구(layers) 중 SimpleRNN과 Dense 도구를 불러오는 명령어\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler # 데이터를 정규화하기 위한 MinMaxScaler 함수를 불러오는 명령어\n",
        "\n",
        "from sklearn.metrics import mean_squared_error # 결과의 정확도를 계산하기 위한 함수인 mean_squared_error를 불러오는 명령어\n",
        "\n",
        "from sklearn.model_selection import train_test_split # 데이터를 훈련 데이터와 검증 데이터로 나누는 명령어\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# 각각 수학 계산을 도와주는 math 라이브러리와 수학 계산 라이브러리인 numpy를 불러온다\n",
        "\n",
        "from pandas import read_csv # csv 파일을 불러올 수 있는 read_csv 함수를 pandas 라이브러리에서 불러오는 명령어"
      ],
      "metadata": {
        "id": "5TUZs4D35N_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/yhlee1627/deeplearning.git # 데이터를 불러오는 코드\n",
        "\n",
        "dataframe = read_csv('/content/deeplearning/corona_daily.csv', usecols=[3], engine='python', skipfooter=3) # 파일을 읽어와서 dataframe 변수에 저장하며, 이때 읽어오는 파일의 형식은 csv 파일\n",
        "\n",
        "print(dataframe) # 읽어온 데이터(dataframe)의 모습을 출력\n",
        "\n",
        "dataset = dataframe.values # 읽어온 데이터(dataframe) 중 우리가 사용할 데이터, 즉 확진자 수 데이터만 가져온다\n",
        "\n",
        "dataset = dataset.astype('float32') # 정규화를 실시할 수 있도록 두 번째 행의 값을 실수로 바꿔준다"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8KIj9CUWa4H",
        "outputId": "cbc7c55b-6b9b-4bab-9d68-24afb8226b6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'deeplearning' already exists and is not an empty directory.\n",
            "     Confirmed\n",
            "0           24\n",
            "1           24\n",
            "2           27\n",
            "3           27\n",
            "4           28\n",
            "..         ...\n",
            "107      11190\n",
            "108      11206\n",
            "109      11225\n",
            "110      11265\n",
            "111      11344\n",
            "\n",
            "[112 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "# 정규화하기 위한 방법을 scaler로 정하고, 이를 위해 사이킷런 라이브러리 중 MinMax Scaler 함수를 사용\n",
        "# 데이터를 정규화하는 범위를 0~1 사이의 값(feature_range=(0, 1))으로 결정\n",
        "\n",
        "Dataset = scaler.fit_transform(dataset)\n",
        "# 정규화 방법인 scaler를 사용한 후, MinMaxScaler 함수 중 fit_trans form 함수를 사용하여 데이터를 정규화\n",
        "# 이렇게 정규화한 데이터를 Dataset으로 정한다\n",
        "\n",
        "train_data, test_data = train_test_split(Dataset, test_size=0.2, shuffle=False)\n",
        "# 인공지능 모델을 만들 때에는 훈련 데이터와 검증 데이터를 사용\n",
        "\n",
        "print(len(train_data), len(test_data))\n",
        "# 훈련 데이터의 개수와 검증 데이터의 개수를 출력하는 코드"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uu8RhcYfYIDP",
        "outputId": "fc37a0ec-0ee8-4277-8b28-4ae91cd757ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(dataset, look_back): # def를 사용하여 create_dataset 함수를 만들어 준다\n",
        "\n",
        "    x_data = []\n",
        "    y_data = []\n",
        "    # 배열([])을 사용하여 각각 x_data와 y_data를 넣을 수 있는 공간을 만든다\n",
        "\n",
        "    for i in range(len(dataset)-look_back-1): # range 함수를 사용하여 몇 번을 반복할지 정해 준다\n",
        "\n",
        "        data = dataset[i:(i+look_back), 0] # 1일차부터 3일차까지의 데이터를 뽑아야 하기 때문에 전체 데이터(dataset)의 첫 번째부터 세 번째까지 열의 데이터를 추출\n",
        "\n",
        "        x_data.append(data) # append 함수를 사용하여 바로 앞에서 추출한 3개의 연속된 데이터(data)를 x_data 배열에 넣어준다\n",
        "\n",
        "        y_data.append(dataset[i + look_back, 0]) # 데이터를 추출하는 과정과 추출할 데이터를 배열에 넣는 과정\n",
        "\n",
        "    return np.array(x_data), np.array(y_data) # 최종적으로 변환된 x_data와 y_data를 모델에서 계산을 쉽게 하도록 넘파이 배열로 바꿔준다"
      ],
      "metadata": {
        "id": "d9pHTyUbey1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "look_back = 3 # 며칠 동안의 연속된 데이터를 바탕으로 인공지능에서 학습할지를 정해주는 코드\n",
        "\n",
        "x_train, y_train = create_dataset(train_data, look_back) \n",
        "# 훈련 데이터를 생성하기 위해 17.4절에서 만든 create_dataset 함수를 호출\n",
        "# 첫 번째 생성되는 x_data를 x_train 데이터로, 두 번째 생성되는 y_data를 y_train 데이터로 넣는다\n",
        "\n",
        "x_test, y_test = create_dataset(test_data, look_back) \n",
        "# 검증 데이터를 생성하기 위해 create_dataset 함수를 호출\n",
        "# 함수에 전달할 인자 중 첫 번째 인자에 검증 데이터(test_data)를 넣는다\n",
        "# 두 번째 인자에 look_back을 넣는다 마찬가지로 첫 번째 생성되는 x_data를 x_test 데이터로, 두 번째 생성되는 y_data를 y_test 데이터로 넣는다\n",
        "\n",
        "print(x_train.shape, y_train.shape) # 훈련 데이터 중 입력 데이터(x_train)의 모습(shape)과 훈련 데이터 중 출력 데이터(y_train)의 모습(shape)\n",
        "\n",
        "print(x_test.shape, y_test.shape) # 검증 데이터 중 입력 데이터(x_test)의 모습(shape)과 검증 데이터 중 출력 데이터(y_test)의 모습(shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFQC1DgGud7t",
        "outputId": "62967d78-2b6b-4c7e-edd3-0ffcb2c64509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(85, 3) (85,)\n",
            "(19, 3) (19,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n",
        "# 넘파이(np) 라이브러리 중 형태를 바꿔 주는 함수(reshape)를 사용하여 훈련 데이터(x_train)의 형태를 바꿔준다\n",
        "# 첫 번째에는 바꿀 데이터(x_train)를, 두 번째에는 어떤 형태로 바꿀지를 넣어준다\n",
        "\n",
        "X_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n",
        "# 검증 데이터(x_test) 역시 같은 방식으로 바꿔준다\n",
        "\n",
        "print(X_train.shape)\n",
        "# 바뀐 형태의 훈련 데이터(x_train)의 모습(shape)\n",
        "\n",
        "print(X_test.shape)\n",
        "# 바뀐 형태의 훈련 데이터(x_test)의 모습(shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taIeFQgb3bCL",
        "outputId": "b0b487e1-fd0c-4803-ac32-48ce03fb1f96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(85, 1, 3)\n",
            "(19, 1, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential() # model이라는 인공지능 모델을 만든다 (이 모델은 시퀀셜 모델이다)\n",
        "\n",
        "model.add(SimpleRNN(3, input_shape=(1, look_back)))\n",
        "# RNN 기법 중 SimpleRNN을 사용\n",
        "# SimpleRNN의 뉴런의 수는 3개(이 값은 변경해도 상관없습니다)이며, 어떤 데이터의 형태를 넣는지(input_shape=(1, look_back))를 결정해준다\n",
        "\n",
        "model.add(Dense(1, activation=\"linear\")) # 최종 예측 값은 연속된 데이터 이후의 값, 즉 확진자의 수\n",
        "\n",
        "model.compile(loss='mse', optimizer='adam')\n",
        "# 인공지능을 계산하는 방법을 결정\n",
        "# 손실 함수는 mse(평균 제곱 오차, mean_squared_error)로, 옵티마이저는 adam 옵티마이저를 사용한다\n",
        "\n",
        "model.summary() # 생성된 모델을 요약"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcPpkDST5Wzv",
        "outputId": "21336ef9-295c-475b-c888-8281b7914e60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_1 (SimpleRNN)    (None, 3)                 21        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25\n",
            "Trainable params: 25\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=100, batch_size=1, verbose=1) # 케라스의 함수를 사용하여 모델을 학습\n",
        "# 입력 데이터(x_train), 출력 데이터(y_train), 반복 횟수(epochs=100), 한 번에 학습시킬 데이터의 양(batch_size=1)을 설정\n",
        "# 학습의 진행 경과는 에포크별 진행 사항을 간단히 알려주는 방식인 verbose=1로 설정"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JI5KPTt7nNX",
        "outputId": "86766417-1737-4492-d08a-d8e9d6b65e5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6.8592e-04\n",
            "Epoch 2/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6.6333e-04\n",
            "Epoch 3/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6.8578e-04\n",
            "Epoch 4/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6.6244e-04\n",
            "Epoch 5/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6.4120e-04\n",
            "Epoch 6/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6.5812e-04\n",
            "Epoch 7/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6.2651e-04\n",
            "Epoch 8/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6.3951e-04\n",
            "Epoch 9/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 5.9864e-04\n",
            "Epoch 10/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6.3457e-04\n",
            "Epoch 11/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6.0636e-04\n",
            "Epoch 12/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6.2664e-04\n",
            "Epoch 13/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6.1471e-04\n",
            "Epoch 14/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 6.2828e-04\n",
            "Epoch 15/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 5.9260e-04\n",
            "Epoch 16/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 5.5938e-04\n",
            "Epoch 17/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 5.8004e-04\n",
            "Epoch 18/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 5.7243e-04\n",
            "Epoch 19/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 5.7534e-04\n",
            "Epoch 20/100\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 5.3068e-04\n",
            "Epoch 21/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 5.8724e-04\n",
            "Epoch 22/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 5.5748e-04\n",
            "Epoch 23/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 5.5993e-04\n",
            "Epoch 24/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 5.3066e-04\n",
            "Epoch 25/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 5.5760e-04\n",
            "Epoch 26/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 5.2395e-04\n",
            "Epoch 27/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 5.8653e-04\n",
            "Epoch 28/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 4.9216e-04\n",
            "Epoch 29/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 5.1128e-04\n",
            "Epoch 30/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 5.2993e-04\n",
            "Epoch 31/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 4.7915e-04\n",
            "Epoch 32/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 4.9116e-04\n",
            "Epoch 33/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 4.8948e-04\n",
            "Epoch 34/100\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 4.6467e-04\n",
            "Epoch 35/100\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 4.8093e-04\n",
            "Epoch 36/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 4.3208e-04\n",
            "Epoch 37/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 4.6633e-04\n",
            "Epoch 38/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 4.6880e-04\n",
            "Epoch 39/100\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 5.0076e-04\n",
            "Epoch 40/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 4.7510e-04\n",
            "Epoch 41/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 4.3105e-04\n",
            "Epoch 42/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 4.5803e-04\n",
            "Epoch 43/100\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 4.2202e-04\n",
            "Epoch 44/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 4.1322e-04\n",
            "Epoch 45/100\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 3.9097e-04\n",
            "Epoch 46/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 4.1747e-04\n",
            "Epoch 47/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 4.0159e-04\n",
            "Epoch 48/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 4.3514e-04\n",
            "Epoch 49/100\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 3.8646e-04\n",
            "Epoch 50/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 4.0527e-04\n",
            "Epoch 51/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 4.1509e-04\n",
            "Epoch 52/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 3.9538e-04\n",
            "Epoch 53/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 3.9002e-04\n",
            "Epoch 54/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 3.9100e-04\n",
            "Epoch 55/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 3.6197e-04\n",
            "Epoch 56/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 3.5289e-04\n",
            "Epoch 57/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 3.4354e-04\n",
            "Epoch 58/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 3.4043e-04\n",
            "Epoch 59/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 3.5402e-04\n",
            "Epoch 60/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 3.5628e-04\n",
            "Epoch 61/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 3.3268e-04\n",
            "Epoch 62/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 3.2404e-04\n",
            "Epoch 63/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 3.2673e-04\n",
            "Epoch 64/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 3.2263e-04\n",
            "Epoch 65/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 3.4617e-04\n",
            "Epoch 66/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 3.1182e-04\n",
            "Epoch 67/100\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 3.1677e-04\n",
            "Epoch 68/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 3.0512e-04\n",
            "Epoch 69/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 3.0021e-04\n",
            "Epoch 70/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 3.1599e-04\n",
            "Epoch 71/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 3.0807e-04\n",
            "Epoch 72/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 2.8162e-04\n",
            "Epoch 73/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 2.8118e-04\n",
            "Epoch 74/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 2.9959e-04\n",
            "Epoch 75/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 2.7733e-04\n",
            "Epoch 76/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 2.6563e-04\n",
            "Epoch 77/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 2.8641e-04\n",
            "Epoch 78/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 2.9072e-04\n",
            "Epoch 79/100\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 2.4982e-04\n",
            "Epoch 80/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 2.4110e-04\n",
            "Epoch 81/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 2.4727e-04\n",
            "Epoch 82/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 2.4963e-04\n",
            "Epoch 83/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 2.3645e-04\n",
            "Epoch 84/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 2.5197e-04\n",
            "Epoch 85/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 2.3886e-04\n",
            "Epoch 86/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 2.5354e-04\n",
            "Epoch 87/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 2.1906e-04\n",
            "Epoch 88/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 2.2946e-04\n",
            "Epoch 89/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 2.1825e-04\n",
            "Epoch 90/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 2.3831e-04\n",
            "Epoch 91/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 1.9928e-04\n",
            "Epoch 92/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 2.3061e-04\n",
            "Epoch 93/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 2.1633e-04\n",
            "Epoch 94/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 2.1060e-04\n",
            "Epoch 95/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 1.9908e-04\n",
            "Epoch 96/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 1.9720e-04\n",
            "Epoch 97/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 1.9457e-04\n",
            "Epoch 98/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 1.8343e-04\n",
            "Epoch 99/100\n",
            "85/85 [==============================] - 0s 2ms/step - loss: 1.9986e-04\n",
            "Epoch 100/100\n",
            "85/85 [==============================] - 0s 1ms/step - loss: 1.8597e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6b862cc9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainPredict = model.predict(X_train)\n",
        "# 케라스에는 생성한 인공지능 모델에 데이터를 넣어서 결괏값을 생성하는 predict 함수가 있다\n",
        "# 이 함수를 사용하여 훈련 데이터(X_train)의 값을 모델에 넣어 값을 예측하고, 그 예측 값을 trainPredict에 넣는다\n",
        "\n",
        "testPredict = model.predict(X_test)\n",
        "# predict 함수를 사용하여 검증 데이터(X_test)의 값을 모델에 넣어 값을 예측한다. 그리고 그 예측 값을 trainPredict에 넣는다\n",
        "\n",
        "TrainPredict = scaler.inverse_transform(trainPredict) \n",
        "# 훈련 데이터의 예측 값(trainPredict)을 scaler 라이브러리의 inverse_transform 함수를 사용하여 0과 1 사이의 값을 정규화하기 전의 확진자의 수로 바꾼다\n",
        "\n",
        "Y_train = scaler.inverse_transform([y_train])\n",
        "# 실제 확진자 수를 나타내는 훈련 데이터(y_train)의 형태를 변형하여 Y_train 변수에 넣는다\n",
        "\n",
        "TestPredict = scaler.inverse_transform(testPredict)\n",
        "# 훈련 데이터의 예측 값, testPredict 변수에 들어 있는 값을 변형하여 TestPredict 변수에 저장한다\n",
        "\n",
        "Y_test = scaler.inverse_transform([y_test]) \n",
        "# 검증 데이터의 형태를 변형하여 Y_test 변수에 넣는다"
      ],
      "metadata": {
        "id": "ib5uKi848RnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainScore = math.sqrt(mean_squared_error(Y_train[0], TrainPredict[:,0]))\n",
        "\n",
        "print('Train Score: %.2f RMSE' % (trainScore))\n",
        "\n",
        "testScore = math.sqrt(mean_squared_error(Y_test[0], TestPredict[:,0]))\n",
        "\n",
        "print('Test Score: %.2f RMSE' % (testScore))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si46EHFb_8U6",
        "outputId": "42ad62a6-3739-4092-c53d-c254fea57717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Score: 145.79 RMSE\n",
            "Test Score: 189.65 RMSE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainPredictPlot = np.empty_like(dataset)\n",
        "trainPredictPlot[:, :] = np.nan\n",
        "trainPredictPlot[look_back:len(TrainPredict)+look_back, :] = TrainPredict\n",
        "testPredictPlot = np.empty_like(dataset)\n",
        "testPredictPlot[:, :] = np.nan\n",
        "plt.plot(dataset)\n",
        "plt.plot(trainPredictPlot)\n",
        "plt.plot(testPredictPlot)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Xo9UwKMvABGr",
        "outputId": "7e06cf03-7352-4bfb-a062-a159fe87cf9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}